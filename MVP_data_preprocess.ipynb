{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BRScraper import nba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing for ML Model\n",
    "\n",
    "# df = nba.get_stats(season=2023, info='per_game', playoffs=False)\n",
    "# drop_columns = ['Age','Pos', 'GS', '3PA', '2PA', 'PF', 'Awards']\n",
    "# df_cleaned = df.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Joel Embiid', 'Nikola Jokić', 'Giannis Antetokounmpo', 'Jayson Tatum', 'Shai Gilgeous-Alexander', 'Donovan Mitchell', 'Domantas Sabonis', 'Luka Dončić', 'Stephen Curry', 'Jimmy Butler', \"De'Aaron Fox\", 'Jalen Brunson', 'Ja Morant']\n"
     ]
    }
   ],
   "source": [
    "# mvp_data = nba.get_award_votings('mvp', 2023)\n",
    "# nominated_players = mvp_data['Player'].tolist()\n",
    "# print(nominated_players)\n",
    "\n",
    "# creating the 'Previously_Nominated' column, if a player was nominated for MVP mark 1, else mark 0. will help serve as a proxy for player reputation\n",
    "# df_cleaned['Previously_Nominated'] = df_cleaned['Player'].apply(lambda x: 1 if x in nominated_players else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # identifying players who have stats for multiple teams and eliminating duplicates\n",
    "# multi_team_players = df_cleaned[df_cleaned['Team'] == '2TM']['Player'].unique()\n",
    "\n",
    "# # keeping only the row where team value is set to 2TM, this row will include all combined stats and average from all teams the player played for\n",
    "# mask = (df_cleaned['Team'] == '2TM') | (~df_cleaned['Player'].isin(multi_team_players))\n",
    "\n",
    "# df_cleaned = df_cleaned[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating a True Shooting Percentage (TS%) column\n",
    "# # the formula is TS% = PTS / 2 * (FGA + 0.44 * FTA)\n",
    "\n",
    "# if 'PTS' in df_cleaned.columns and 'FGA' in df_cleaned.columns and 'FTA' in df_cleaned.columns:\n",
    "#     df_cleaned['TS%'] = df_cleaned['PTS'] / (2 * (df_cleaned['FGA'] + 0.44 * df_cleaned['FTA']))\n",
    "#     df_cleaned['TS%'] = df_cleaned['TS%'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding another column EEF, stands effeciency. It a metric used by the nba to calculate a player's efficiency or impact.\n",
    "\n",
    "# # calculating missed field goals and missed free throws because the EEF formula requires it.\n",
    "# df_cleaned['Missed_FG'] = df_cleaned['FGA'] - df_cleaned['FG']\n",
    "# df_cleaned['Missed_FT'] = df_cleaned['FTA'] - df_cleaned['FT']\n",
    "\n",
    "# # Calculating EFF\n",
    "# df_cleaned['EFF'] = (\n",
    "#     df_cleaned['PTS'] +\n",
    "#     df_cleaned['TRB'] +\n",
    "#     df_cleaned['AST'] +\n",
    "#     df_cleaned['STL'] +\n",
    "#     df_cleaned['BLK'] -\n",
    "#     df_cleaned['Missed_FG'] -\n",
    "#     df_cleaned['Missed_FT'] -\n",
    "#     df_cleaned['TOV']\n",
    "#     ) / df_cleaned['G']\n",
    "\n",
    "# # dropping the temporary columns, no longer needed\n",
    "# df_cleaned.drop(columns=['Missed_FG', 'Missed_FT'], inplace=True)\n",
    "\n",
    "# # rounded EFF to 2 decimals\n",
    "# df_cleaned['EFF'] = df_cleaned['EFF'].round(2)\n",
    "\n",
    "# output_file = \"nba_2023_adjusted_data.csv\"\n",
    "# df_cleaned.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1980-81 successfully!\n",
      "Processed 1981-82 successfully!\n",
      "Processed 1982-83 successfully!\n",
      "Processed 1983-84 successfully!\n",
      "Processed 1984-85 successfully!\n",
      "Processed 1985-86 successfully!\n",
      "Processed 1986-87 successfully!\n",
      "Processed 1987-88 successfully!\n",
      "Processed 1988-89 successfully!\n",
      "Processed 1989-90 successfully!\n",
      "Processed 1990-91 successfully!\n",
      "Processed 1991-92 successfully!\n",
      "Processed 1992-93 successfully!\n",
      "Processed 1993-94 successfully!\n",
      "Processed 1994-95 successfully!\n",
      "Processed 1995-96 successfully!\n",
      "Processed 1996-97 successfully!\n",
      "Processed 1997-98 successfully!\n",
      "Processed 1998-99 successfully!\n",
      "Processed 1999-00 successfully!\n",
      "Processed 2000-01 successfully!\n",
      "Processed 2001-02 successfully!\n",
      "Processed 2002-03 successfully!\n",
      "Processed 2003-04 successfully!\n",
      "Processed 2004-05 successfully!\n",
      "Processed 2005-06 successfully!\n",
      "Processed 2006-07 successfully!\n",
      "Processed 2007-08 successfully!\n",
      "Processed 2008-09 successfully!\n",
      "Processed 2009-10 successfully!\n",
      "Processed 2010-11 successfully!\n",
      "Processed 2011-12 successfully!\n",
      "Processed 2012-13 successfully!\n",
      "Processed 2013-14 successfully!\n",
      "Processed 2014-15 successfully!\n",
      "Processed 2015-16 successfully!\n",
      "Processed 2016-17 successfully!\n",
      "Processed 2017-18 successfully!\n",
      "Processed 2018-19 successfully!\n",
      "Processed 2019-20 successfully!\n",
      "Processed 2020-21 successfully!\n",
      "Processed 2021-22 successfully!\n",
      "Processed 2022-23 successfully!\n",
      "Processed 2023-24 successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to preprocess a single season\n",
    "def preprocess_season(file_name, season):\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    drop_columns = ['Age', 'Pos', 'GS', '3PA', '2PA', 'PF', 'Awards']\n",
    "    df_cleaned = df.drop(columns=drop_columns, errors='ignore')\n",
    "    \n",
    "    # Load MVP data for the season\n",
    "    try:\n",
    "        mvp_data = nba.get_award_votings('mvp', season)\n",
    "        nominated_players = mvp_data['Player'].tolist()\n",
    "    except Exception:\n",
    "        nominated_players = []  # If MVP data is not available, leave this empty\n",
    "\n",
    "    # Add 'Previously_Nominated' column\n",
    "    df_cleaned['Previously_Nominated'] = df_cleaned['Player'].apply(\n",
    "        lambda x: 1 if x in nominated_players else 0\n",
    "    )\n",
    "\n",
    "    # Handle players who played for multiple teams\n",
    "    multi_team_players = df_cleaned[df_cleaned['Team'] == '2TM']['Player'].unique()\n",
    "    mask = (df_cleaned['Team'] == '2TM') | (~df_cleaned['Player'].isin(multi_team_players))\n",
    "    df_cleaned = df_cleaned[mask]\n",
    "\n",
    "    # Calculate TS%\n",
    "    if 'PTS' in df_cleaned.columns and 'FGA' in df_cleaned.columns and 'FTA' in df_cleaned.columns:\n",
    "        df_cleaned['TS%'] = df_cleaned['PTS'] / (2 * (df_cleaned['FGA'] + 0.44 * df_cleaned['FTA']))\n",
    "        df_cleaned['TS%'] = df_cleaned['TS%'].round(2)\n",
    "\n",
    "    # Calculate missed shots for EFF\n",
    "    if 'FGA' in df_cleaned.columns and 'FG' in df_cleaned.columns:\n",
    "        df_cleaned['Missed_FG'] = df_cleaned['FGA'] - df_cleaned['FG']\n",
    "    if 'FTA' in df_cleaned.columns and 'FT' in df_cleaned.columns:\n",
    "        df_cleaned['Missed_FT'] = df_cleaned['FTA'] - df_cleaned['FT']\n",
    "\n",
    "    # Calculate EFF\n",
    "    if {'PTS', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'G', 'Missed_FG', 'Missed_FT'}.issubset(df_cleaned.columns):\n",
    "        df_cleaned['EFF'] = (\n",
    "            df_cleaned['PTS'] +\n",
    "            df_cleaned['TRB'] +\n",
    "            df_cleaned['AST'] +\n",
    "            df_cleaned['STL'] +\n",
    "            df_cleaned['BLK'] -\n",
    "            df_cleaned['Missed_FG'] -\n",
    "            df_cleaned['Missed_FT'] -\n",
    "            df_cleaned['TOV']\n",
    "        ) / df_cleaned['G']\n",
    "        df_cleaned['EFF'] = df_cleaned['EFF'].round(2)\n",
    "\n",
    "    # Drop temporary columns\n",
    "    df_cleaned.drop(columns=['Missed_FG', 'Missed_FT'], inplace=True, errors='ignore')\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "# Loop through all season files\n",
    "input_folder = \"\"  # Root folder\n",
    "output_folder = \"processed_data\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for year in range(1980, 2024):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}nba_player_stats_{season}.csv\"\n",
    "    output_file = f\"{output_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            processed_df = preprocess_season(file_name, year)\n",
    "            processed_df.to_csv(output_file, index=False)\n",
    "            print(f\"Processed {season} successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {season}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {file_name} not found. Skipping.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
