{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BRScraper import nba\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 multi-team player rows.\n",
      "Processed 1980-81 successfully!\n",
      "Found 28 multi-team player rows.\n",
      "Processed 1981-82 successfully!\n",
      "Found 36 multi-team player rows.\n",
      "Processed 1982-83 successfully!\n",
      "Found 15 multi-team player rows.\n",
      "Processed 1983-84 successfully!\n",
      "Found 20 multi-team player rows.\n",
      "Processed 1984-85 successfully!\n",
      "Found 25 multi-team player rows.\n",
      "Processed 1985-86 successfully!\n",
      "Found 21 multi-team player rows.\n",
      "Processed 1986-87 successfully!\n",
      "Found 46 multi-team player rows.\n",
      "Processed 1987-88 successfully!\n",
      "Found 42 multi-team player rows.\n",
      "Processed 1988-89 successfully!\n",
      "Found 38 multi-team player rows.\n",
      "Processed 1989-90 successfully!\n",
      "Found 26 multi-team player rows.\n",
      "Processed 1990-91 successfully!\n",
      "Found 33 multi-team player rows.\n",
      "Processed 1991-92 successfully!\n",
      "Found 28 multi-team player rows.\n",
      "Processed 1992-93 successfully!\n",
      "Found 37 multi-team player rows.\n",
      "Processed 1993-94 successfully!\n",
      "Found 22 multi-team player rows.\n",
      "Processed 1994-95 successfully!\n",
      "Found 56 multi-team player rows.\n",
      "Processed 1995-96 successfully!\n",
      "Found 63 multi-team player rows.\n",
      "Processed 1996-97 successfully!\n",
      "Found 53 multi-team player rows.\n",
      "Processed 1997-98 successfully!\n",
      "Found 33 multi-team player rows.\n",
      "Processed 1998-99 successfully!\n",
      "Found 28 multi-team player rows.\n",
      "Processed 1999-00 successfully!\n",
      "Found 47 multi-team player rows.\n",
      "Processed 2000-01 successfully!\n",
      "Found 30 multi-team player rows.\n",
      "Processed 2001-02 successfully!\n",
      "Found 27 multi-team player rows.\n",
      "Processed 2002-03 successfully!\n",
      "Found 68 multi-team player rows.\n",
      "Processed 2003-04 successfully!\n",
      "Found 59 multi-team player rows.\n",
      "Processed 2004-05 successfully!\n",
      "Found 51 multi-team player rows.\n",
      "Processed 2005-06 successfully!\n",
      "Found 29 multi-team player rows.\n",
      "Processed 2006-07 successfully!\n",
      "Found 68 multi-team player rows.\n",
      "Processed 2007-08 successfully!\n",
      "Found 67 multi-team player rows.\n",
      "Processed 2008-09 successfully!\n",
      "Found 66 multi-team player rows.\n",
      "Processed 2009-10 successfully!\n",
      "Found 83 multi-team player rows.\n",
      "Processed 2010-11 successfully!\n",
      "Found 36 multi-team player rows.\n",
      "Processed 2011-12 successfully!\n",
      "Found 50 multi-team player rows.\n",
      "Processed 2012-13 successfully!\n",
      "Found 63 multi-team player rows.\n",
      "Processed 2013-14 successfully!\n",
      "Found 76 multi-team player rows.\n",
      "Processed 2014-15 successfully!\n",
      "Found 50 multi-team player rows.\n",
      "Processed 2015-16 successfully!\n",
      "Found 53 multi-team player rows.\n",
      "Processed 2016-17 successfully!\n",
      "Found 59 multi-team player rows.\n",
      "Processed 2017-18 successfully!\n",
      "Found 86 multi-team player rows.\n",
      "Processed 2018-19 successfully!\n",
      "Found 60 multi-team player rows.\n",
      "Processed 2019-20 successfully!\n",
      "Found 79 multi-team player rows.\n",
      "Processed 2020-21 successfully!\n",
      "Found 97 multi-team player rows.\n",
      "Processed 2021-22 successfully!\n",
      "Found 70 multi-team player rows.\n",
      "Processed 2022-23 successfully!\n",
      "Found 78 multi-team player rows.\n",
      "Processed 2023-24 successfully!\n",
      "No multi-team players found in the dataset.\n",
      "Processed 2024-25 successfully!\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess a single season\n",
    "def preprocess_season(file_name, year):\n",
    "    df = pd.read_csv(file_name)\n",
    "\n",
    "# Handle players who played for multiple teams\n",
    "    # Create a dictionary to store multi-team player data (including players with 2TM, 3TM, etc.)\n",
    "    multi_team_dict = {}\n",
    "\n",
    "    # Identify players with 'TM' in their 'Team' column (multi-team players)\n",
    "    multi_team_rows = df[df['Team'].str.contains('TM', na=False)]\n",
    "\n",
    "    # Check if there are any multi-team players\n",
    "    if multi_team_rows.empty:\n",
    "        print(\"No multi-team players found in the dataset.\")\n",
    "    else:\n",
    "        print(f\"Found {len(multi_team_rows)} multi-team player rows.\")\n",
    "\n",
    "    # For each multi-team player, gather all teams they played for (excluding 2TM, 3TM, etc.)\n",
    "    for player in multi_team_rows['Player'].unique():\n",
    "        player_teams = df[(df['Player'] == player) & ~df['Team'].str.contains('TM', na=False)]['Team'].tolist()\n",
    "        multi_team_dict[player] = ', '.join(player_teams)\n",
    "\n",
    "    # Remove duplicate rows for multi-team players and keep the rows with 'TM' in the Team column\n",
    "    multi_team_players = multi_team_rows['Player'].unique()\n",
    "    mask = (df['Team'].str.contains('TM', na=False)) | (~df['Player'].isin(multi_team_players))\n",
    "    df = df[mask]\n",
    "\n",
    "    # Add the 'Multiple Teams' column using the mapping from the multi_team_dict\n",
    "    df['Multiple Teams'] = df['Player'].map(multi_team_dict)\n",
    "\n",
    "    # Fill NaN values in the 'Multiple Teams' column with an empty string\n",
    "    df.fillna({'Multiple Teams': ''}, inplace=True)\n",
    "\n",
    "    # Reorder columns to place 'Multiple Teams' between 'Team' and 'Pos'\n",
    "    columns = list(df.columns)\n",
    "    if 'Multiple Teams' in columns and 'Team' in columns:\n",
    "        team_index = columns.index('Team')  # Get the index of 'Team' column\n",
    "        columns.insert(team_index + 1, columns.pop(columns.index('Multiple Teams')))  # Reorder columns\n",
    "        df = df[columns]\n",
    "\n",
    "\n",
    "\n",
    "# Addition of the TS% feature\n",
    "    # Drop unnecessary columns\n",
    "    drop_columns = ['Age', 'Pos', 'GS', '3PA', '2PA', 'PF']\n",
    "    df_cleaned = df.drop(columns=drop_columns, errors='ignore')\n",
    "\n",
    "    # Calculate TS%\n",
    "    if 'PTS' in df_cleaned.columns and 'FGA' in df_cleaned.columns and 'FTA' in df_cleaned.columns:\n",
    "        df_cleaned['TS%'] = df_cleaned['PTS'] / (2 * (df_cleaned['FGA'] + 0.44 * df_cleaned['FTA']))\n",
    "        df_cleaned['TS%'] = df_cleaned['TS%'].round(2)\n",
    "\n",
    "\n",
    "# Addition of the EFF feature\n",
    "    # Calculate missed shots for EFF\n",
    "    if 'FGA' in df_cleaned.columns and 'FG' in df_cleaned.columns:\n",
    "        df_cleaned['Missed_FG'] = df_cleaned['FGA'] - df_cleaned['FG']\n",
    "    if 'FTA' in df_cleaned.columns and 'FT' in df_cleaned.columns:\n",
    "        df_cleaned['Missed_FT'] = df_cleaned['FTA'] - df_cleaned['FT']\n",
    "\n",
    "    # Calculate EFF\n",
    "    if {'PTS', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'G', 'Missed_FG', 'Missed_FT'}.issubset(df_cleaned.columns):\n",
    "        df_cleaned['EFF'] = (\n",
    "            df_cleaned['PTS'] +\n",
    "            df_cleaned['TRB'] +\n",
    "            df_cleaned['AST'] +\n",
    "            df_cleaned['STL'] +\n",
    "            df_cleaned['BLK'] -\n",
    "            df_cleaned['Missed_FG'] -\n",
    "            df_cleaned['Missed_FT'] -\n",
    "            df_cleaned['TOV']\n",
    "        ) / df_cleaned['G']\n",
    "        df_cleaned['EFF'] = df_cleaned['EFF'].round(2)\n",
    "\n",
    "    # Drop temporary columns\n",
    "    df_cleaned.drop(columns=['Missed_FG', 'Missed_FT'], inplace=True, errors='ignore')\n",
    "    \n",
    "    \n",
    "    \n",
    "# Addition of the MVP feature, ROY feature, AS feature, and All-NBA feature\n",
    "    # Define award categories\n",
    "    mvp_awards = [f'MVP-{i}' for i in range(1, 11)]\n",
    "    dpoy_awards = [f'DPOY-{i}' for i in range(1, 11)]\n",
    "    six_moy_awards = [f'6MOY-{i}' for i in range(1, 6)]\n",
    "    roy_awards = [f'ROY-{i}' for i in range(1, 6)]\n",
    "    all_nba_awards = ['NBA1', 'NBA2', 'NBA3']\n",
    "    as_awards = ['AS']\n",
    "    \n",
    "    # Initialize new columns with empty strings\n",
    "    df_cleaned['MVP'] = ''\n",
    "    df_cleaned['DPOY'] = ''\n",
    "    df_cleaned['6MOY'] = ''\n",
    "    df_cleaned['ROY'] = ''\n",
    "    df_cleaned['AS'] = ''\n",
    "    df_cleaned['All-NBA'] = ''\n",
    "\n",
    "    # Function to extract awards based on categories\n",
    "    def extract_awards(awards_string, category_list):\n",
    "        if pd.isna(awards_string):\n",
    "            return ''\n",
    "        awards = [award.strip() for award in awards_string.split(',')]\n",
    "        filtered_awards = [award for award in awards if award in category_list]\n",
    "        return ','.join(filtered_awards)\n",
    "\n",
    "    # Apply the function to split awards into respective columns\n",
    "    df_cleaned['MVP'] = df_cleaned['Awards'].apply(lambda x: extract_awards(x, mvp_awards))\n",
    "    df_cleaned['DPOY'] = df_cleaned['Awards'].apply(lambda x: extract_awards(x, dpoy_awards))\n",
    "    df_cleaned['6MOY'] = df_cleaned['Awards'].apply(lambda x: extract_awards(x, six_moy_awards))\n",
    "    df_cleaned['ROY'] = df_cleaned['Awards'].apply(lambda x: extract_awards(x, roy_awards))\n",
    "    df_cleaned['AS'] = df_cleaned['Awards'].apply(lambda x: extract_awards(x, as_awards))\n",
    "    df_cleaned['All-NBA'] = df_cleaned['Awards'].apply(lambda x: extract_awards(x, all_nba_awards))\n",
    "\n",
    "    # One-hot encode 'AS' (All-Star) feature\n",
    "    df_cleaned['AS'] = df_cleaned['AS'].apply(lambda x: 1 if x == 'AS' else 0)\n",
    "\n",
    "    # Apply numeric values for 'MVP', 'ROY', and 'All-NBA' values\n",
    "    # MVP - Using lambda to assign numbers based on MVP-1, MVP-2, ..., MVP-10\n",
    "    df_cleaned['MVP'] = df_cleaned['MVP'].apply(lambda x: 10 if 'MVP-10' in str(x) else\n",
    "                                            (9 if 'MVP-9' in str(x) else\n",
    "                                             (8 if 'MVP-8' in str(x) else\n",
    "                                              (7 if 'MVP-7' in str(x) else\n",
    "                                               (6 if 'MVP-6' in str(x) else\n",
    "                                                (5 if 'MVP-5' in str(x) else\n",
    "                                                 (4 if 'MVP-4' in str(x) else\n",
    "                                                  (3 if 'MVP-3' in str(x) else\n",
    "                                                   (2 if 'MVP-2' in str(x) else\n",
    "                                                    (1 if 'MVP-1' in str(x) else\n",
    "                                                     0))))))))))\n",
    "    \n",
    "    # DPOY - Using lambda to assign numbers based on DPOY-1, DPOY-2, ..., DPOY-10\n",
    "    df_cleaned['DPOY'] = df_cleaned['DPOY'].apply(lambda x: 10 if 'DPOY-10' in str(x) else\n",
    "                                            (9 if 'DPOY-9' in str(x) else\n",
    "                                             (8 if 'DPOY-8' in str(x) else\n",
    "                                              (7 if 'DPOY-7' in str(x) else\n",
    "                                               (6 if 'DPOY-6' in str(x) else\n",
    "                                                (5 if 'DPOY-5' in str(x) else\n",
    "                                                 (4 if 'DPOY-4' in str(x) else\n",
    "                                                  (3 if 'DPOY-3' in str(x) else\n",
    "                                                   (2 if 'DPOY-2' in str(x) else\n",
    "                                                    (1 if 'DPOY-1' in str(x) else\n",
    "                                                     0))))))))))\n",
    "\n",
    "    # 6MOY - Using lambda to assign numbers based on 6MOY-1, 6MOY-2, ..., 6MOY-5\n",
    "    df_cleaned['6MOY'] = df_cleaned['6MOY'].apply(lambda x: 5 if '6MOY-5' in str(x) else\n",
    "                                         (4 if '6MOY-4' in str(x) else\n",
    "                                          (3 if '6MOY-3' in str(x) else\n",
    "                                           (2 if '6MOY-2' in str(x) else\n",
    "                                            (1 if '6MOY-1' in str(x) else 0)))))\n",
    "\n",
    "    # ROY - Using lambda to assign numbers based on ROY-1, ROY-2, ..., ROY-5\n",
    "    df_cleaned['ROY'] = df_cleaned['ROY'].apply(lambda x: 5 if 'ROY-5' in str(x) else\n",
    "                                         (4 if 'ROY-4' in str(x) else\n",
    "                                          (3 if 'ROY-3' in str(x) else\n",
    "                                           (2 if 'ROY-2' in str(x) else\n",
    "                                            (1 if 'ROY-1' in str(x) else 0)))))\n",
    "\n",
    "    # All-NBA - Using lambda to assign numbers based on NBA1, NBA2\n",
    "    df_cleaned['All-NBA'] = df_cleaned['All-NBA'].apply(lambda x: 3 if 'NBA3' in str(x) else\n",
    "                                            (2 if 'NBA2' in str(x) else\n",
    "                                             (1 if 'NBA1' in str(x) else 0)))\n",
    "\n",
    "    \n",
    "\n",
    "# Addition of the MVP_count feature\n",
    "    # Add MVP_count column\n",
    "    df_cleaned['MVP_count'] = 0\n",
    "    mvp_df = pd.read_csv('nba_player_stats_mvp_data.csv')\n",
    "\n",
    "    # Extract the starting year from the 'season' column in mvp_df\n",
    "    mvp_df['season_start'] = mvp_df['Season'].str.split('-').str[0].astype(int)\n",
    "\n",
    "    # Filter MVP data for seasons before the current year\n",
    "    prior_mvp_df = mvp_df[mvp_df['season_start'] < year]\n",
    "\n",
    "    # Count MVP wins per player\n",
    "    mvp_counts = prior_mvp_df['Player'].value_counts().to_dict()  # {player_name: mvp_count}\n",
    "\n",
    "    # Map MVP counts to the current season's players\n",
    "    df_cleaned['MVP_count'] = df_cleaned['Player'].map(mvp_counts).fillna(0).astype(int)\n",
    "    \n",
    "    \n",
    "# Addition of the MVP_nominations feature\n",
    "    # Add MVP_nominations column\n",
    "    df_cleaned['MVP_nominations'] = 0\n",
    "    \n",
    "    # Cumulative nomination tracker: {player_name: total_nominations}\n",
    "    cumulative_nominations = {}\n",
    "     \n",
    "    for each_year in range(year - 1, 1979, -1):\n",
    "        current_season = f\"{each_year}-{str(each_year+1)[-2:]}\"\n",
    "        file_in = f\"{\"untouched_seasonal_data\"}/nba_player_stats_{current_season}.csv\"\n",
    "        \n",
    "        if os.path.exists(file_in):\n",
    "            this_df = pd.read_csv(file_in)\n",
    "            \n",
    "            # Check the awards column for MVP nominations (mvp-1 to mvp-10)\n",
    "            if 'Awards' in this_df.columns:\n",
    "                for _, row in this_df.iterrows():\n",
    "                    player = row['Player']\n",
    "                    awards = str(row.get('Awards', ''))  # Get the awards column, default to an empty string\n",
    "                \n",
    "                    # Check if the player was nominated for MVP\n",
    "                    if any(f\"mvp-{i}\" in awards.lower() for i in range(1, 11)):\n",
    "                        # Increment cumulative nominations for the player\n",
    "                        cumulative_nominations[player] = cumulative_nominations.get(player, 0) + 1\n",
    "            \n",
    "    # Add the cumulative nominations from prior years to the current dataset\n",
    "    df_cleaned['MVP_nominations'] = df_cleaned['Player'].map(cumulative_nominations).fillna(0).astype(int)   \n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "\n",
    "# Define the folder containing the CSV files and desired output\n",
    "input_folder = \"untouched_seasonal_data\"\n",
    "output_folder = \"processed_data\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for year in range(1980, 2025):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}.csv\"\n",
    "    output_file = f\"{output_folder}/nba_player_stats_{season}_processed.csv\"    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            processed_df = preprocess_season(file_name, year)\n",
    "            processed_df.to_csv(output_file, index=False)\n",
    "            print(f\"Processed {season} successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {season}: {e}\")\n",
    "    else:\n",
    "        print(f\"File {file_name} not found. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocessed the data to include two new features to help predict the MVP Ranking from 1-10. all other players will have NaN. From the new preprocessed datasets for each year from 1980 to 2023 we can create models to predict MVP Rank for each play and compare for each model how well it predicts to actual winners for each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data for the 1980 season\n",
      "Successfully read data for the 1981 season\n",
      "Successfully read data for the 1982 season\n",
      "Successfully read data for the 1983 season\n",
      "Successfully read data for the 1984 season\n",
      "Successfully read data for the 1985 season\n",
      "Successfully read data for the 1986 season\n",
      "Successfully read data for the 1987 season\n",
      "Successfully read data for the 1988 season\n",
      "Successfully read data for the 1989 season\n",
      "Successfully read data for the 1990 season\n",
      "Successfully read data for the 1991 season\n",
      "Successfully read data for the 1992 season\n",
      "Successfully read data for the 1993 season\n",
      "Successfully read data for the 1994 season\n",
      "Successfully read data for the 1995 season\n",
      "Successfully read data for the 1996 season\n",
      "Successfully read data for the 1997 season\n",
      "Successfully read data for the 1998 season\n",
      "Successfully read data for the 1999 season\n",
      "Successfully read data for the 2000 season\n",
      "Successfully read data for the 2001 season\n",
      "Successfully read data for the 2002 season\n",
      "Successfully read data for the 2003 season\n",
      "Successfully read data for the 2004 season\n",
      "Successfully read data for the 2005 season\n",
      "Successfully read data for the 2006 season\n",
      "Successfully read data for the 2007 season\n",
      "Successfully read data for the 2008 season\n",
      "Successfully read data for the 2009 season\n",
      "Successfully read data for the 2010 season\n",
      "Successfully read data for the 2011 season\n",
      "Successfully read data for the 2012 season\n",
      "Successfully read data for the 2013 season\n",
      "Successfully read data for the 2014 season\n",
      "Successfully read data for the 2015 season\n",
      "All datasets have been concatenated and saved to 'nba_combined_1980_2015.csv'.\n"
     ]
    }
   ],
   "source": [
    "#Combine all datasets from 1980 to 2015\n",
    "# Define the folder containing the CSV files\n",
    "input_folder = \"processed_data\"\n",
    "\n",
    "# List to hold dataframes\n",
    "dataframes = []\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through each year from 1980 to 2015\n",
    "for year in range(1980, 2016):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # Read the dataset for the year\n",
    "            df = pd.read_csv(file_name)\n",
    "        \n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(df)\n",
    "        \n",
    "            print(f\"Successfully read data for the {year} season\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read data for {year} season. Error: {e}\")\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to a CSV file\n",
    "combined_df.to_csv(\"nba_combined_1980_2015.csv\", index=False)\n",
    "\n",
    "print(\"All datasets have been concatenated and saved to 'nba_combined_1980_2015.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data for the 2016 season\n",
      "Successfully read data for the 2017 season\n",
      "Successfully read data for the 2018 season\n",
      "Successfully read data for the 2019 season\n",
      "Successfully read data for the 2020 season\n",
      "Successfully read data for the 2021 season\n",
      "Successfully read data for the 2022 season\n",
      "Successfully read data for the 2023 season\n",
      "Successfully read data for the 2024 season\n",
      "All datasets have been concatenated and saved to 'nba_combined_2016_2024.csv'.\n"
     ]
    }
   ],
   "source": [
    "#Combine all datasets from 2016 to 2024\n",
    "# Define the folder containing the CSV files\n",
    "input_folder = \"processed_data\"\n",
    "\n",
    "# List to hold dataframes\n",
    "dataframes = []\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through each year from 2016 to 2024\n",
    "for year in range(2016, 2025):\n",
    "    season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "    file_name = f\"{input_folder}/nba_player_stats_{season}_processed.csv\"\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            # Read the dataset for the year\n",
    "            df = pd.read_csv(file_name)\n",
    "        \n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(df)\n",
    "        \n",
    "            print(f\"Successfully read data for the {year} season\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read data for {year} season. Error: {e}\")\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to a CSV file\n",
    "combined_df.to_csv(\"nba_combined_2016_2024.csv\", index=False)\n",
    "\n",
    "print(\"All datasets have been concatenated and saved to 'nba_combined_2016_2024.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
